{
  "id": "blog-7",
  "title": "大匠运斤 - 应用层缓存设计",
  "digest": {
    "articleUrl": "/page/tech/blog/blog-7/blog-7.html",
    "content": "缓存设计是高并发系统架构的重中之重，合理使用缓存可以提升应用的访问速度和并发能力。本文将总结架构体系中应用层的缓存设计与落地方案。",
    "picUrl": "/page/tech/pic/cache.jpeg",
    "tag": "架构",
    "title": "大匠运斤 - 应用层缓存设计"
  },
  "navType": "BLOG",
  "phases": [
    {
      "title": "前言",
      "segment": [
        "缓存设计是高并发系统架构的重中之重，合理使用缓存可以提升应用的访问速度和并发能力。本文将总结缓存在架构体系中应用层的设计与落地方案。"
      ]
    },
    {
      "title": "目的",
      "segment": [
        "引入缓存的目的可概括为3点：",
        "1 引入缓存可减少低速数据源的访问，提升访问效率。eg：CPU访问热点数据的顺序是寄存器、内存、硬盘",
        "2 引入缓存可从更靠近请求方的地方拿到数据，提升访问效率。eg：maven仓库依赖加载顺序为本地仓库、本地服务器、远程服务器；",
        "3 引入缓存可缓解负载能力较弱的应用所承受的压力，提升系统可用性。eg：Web请求优先访问缓存，而不是直接访问并发能力较弱的数据库"
      ]
    },
    {
      "title": "设计思路",
      "segment": [
        "Cache-Aside：业务整合缓存逻辑，这是缓存设计的常规思路。实现方式为 -> 读操作分三步走，读缓存，没有则读库并将结果存入缓存；写操作有两种，当数据更新后，可选择将已有缓存清除或者更新。",
        "Cache-As-Sor：业务将数据操作代理给缓存处理器，这是设计实现里稍为复杂的一种思路。读库逻辑全部封装到缓存处理器中，对业务透明。缓存处理器内部封装的数据逻辑为 -> 读缓存，没有则读库并将结果存入缓存；写缓存，具体操作委托给处理器，处理器来双写缓存和库。这种模式很好的分离了业务逻辑和缓存逻辑，我们可以将批操作、多线程、异步等提升性能的技术引入到处理器中，既提升了性能，又不会侵入到业务代码。"
      ]
    },
    {
      "title": "实现方式",
      "segment": [
        "缓存的实现方式有很多，建议借助成熟的工具如Guava、EhCache来包装自己的缓存工具，而不是完全由自己编写。在学习缓存工具之前，最好先了解下缓存的介质类型。常见的Java缓存介质包括JVM堆、直接内存、磁盘、分布式缓存。",
        "JVM堆：本地缓存一般基于JVM堆实现，优点是简单易用高效且不需要序列化；缺点是不适合大数据量的场景，因为数据量过大会导致GC暂停时间拉长；自己实现本地缓存时，可结合软引用、弱引用来优化内存安全，如无特殊需求，可使用Google提供的Guava来实现本地缓存。",
        "直接内存：本地缓存也可基于直接内存实现，优点是效率较高效且不会拖累GC，但直接内存需要序列化，一定程度上影响了缓存的使用效率",
        "磁盘：磁盘缓存的优点是持久化数据不易失，缺点是效率低速度慢，不适合单独作为缓存使用。",
        "分布式缓存：分布式缓存最大的优点是容量可扩展，缺点是引入和分布式复杂性（网络问题、一致性问题等）且需要序列化",
        "大型分布式系统在设计缓存时需将各种介质配合使用：核心热点数据存储在本地内存，普通热点数据使用直接内存，全量数据则存放在分布式缓存中，并按需将部分缓存数据持久化在硬盘中。"
      ]
    },
    {
      "title": "实践重点",
      "segment": [
        "防止缓存穿透：缓存穿透指的是缓存层不存储查询结果为空的结果集，导致每次查询都会查询数据库。（eg：请求先查缓存，缓存中没有则查库，库里没有给请求返回空）解决方法：将空结果集以占位符的方式设置到缓存中去（eg：请求先查缓存，缓存中没有则查库，库里没有就给请求返回空，且将一个表示空的占位符缓存起来，这样下次同样的请求，查询缓存时就能查到这个空占位符，直接返回空给请求，防止进一步查库）",
        "防止缓存雪崩：缓存雪崩指的是缓存在某个较短时间段内大规模失效，导致大量请求直接落到数据库上。导致缓存雪崩的常见原因有：a 大量缓存的加载时间和失效时间一致，解决办法 -> 打散失效时间；b 缓存系统挂掉，解决办法1 -> 提升缓存系统可用性，组成集群以防止单点故障。解决办法2 ->增加降级预案，引流到其他数据源。解决办法3 -> 限流，防止流量打爆数据库。解决办法4 -> 预热，在缓存雪崩发生后，采用上述三种办法并手动预热数据。",
        "防止缓存击穿：热点数据失效时，大量请求访问会击穿缓存并重建热点数据，如果这个热点数据是IO复杂（耗时查库）或计算复杂（耗时计算）的，那么多个不同的请求线程均去重建同一份数据很明显是无意义且加大了系统的负担，这种情况下需要引入一把锁去锁住重建过程，只让一个请求去重建热点数据，其他请求再使用即可。在热点缓存一致性要求不高的情况下，还有种更简单的方案是将热点缓存设为永不失效，然后开启额外的线程专门来更新热点缓存。",
        "缓存全局控制：可将强刷缓存、禁用缓存等缓存全局控制配置成开关",
        "设置淘汰机制：缓存空间占满时，需要淘汰部分数据以支持新的缓存需求。常见的淘汰方式有 FIFO方式 -> 最老的数据被淘汰。当数据实时性要求很高的情况下可采用此方式；LFU方式 -> 最少使用的优先淘汰。这种方式可以保证高频访问的数据被留下；LRU：最近最少使用的被淘汰。为每个数据记下最后一次访问的时间戳，优先淘汰时间戳最小的数据；",
        "缓存更新检查：当数据量较大时，请求方可以自己缓存一份数据到本地，只有当数据变化时再拉取服务方的新数据。监控数据变化的方式是引入版本机制，为缓存的数据标记一个版本标识，如最后更新时间。请求方每次发起数据请求都携带一个当前版本号，若版本号和服务方的版本号不一致时才拉取数据，避免大量无意义的数据传输；"
      ]
    }
  ]
}
